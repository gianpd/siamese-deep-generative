{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import skimage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tf_from_path(\n",
    "    img_path: typing.Union[str, pathlib.Path], \n",
    "    resizeSize: typing.Optional[tuple] = None,\n",
    "    resizeMethod: typing.Optional[str] = tf.image.ResizeMethod.LANCZOS3) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Load a tf.Tensor from disk.\n",
    "\n",
    "    --- Parameters ---\n",
    "        img_path: path of the image (str or pathlib.Path)\n",
    "        resizeSize: optional tuple containing width and height of the target resize\n",
    "        resizeMethod: resize method to be used (LANCZOS3 default)\n",
    "    \"\"\"\n",
    "    img = tf.io.read_file(img_path) if isinstance(img_path, str) else tf.io.read_file(str(img_path))\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    if resizeSize:\n",
    "        img = tf.image.resize(img, size=resizeSize, method=resizeMethod) \n",
    "        img = tf.cast(tf.round(tf.clip_by_value(img, 0, 255)), dtype=tf.uint8)\n",
    "    return tf.expand_dims(img, axis=0) # return a Tensor with shape [1, width, height, channels]\n",
    "\n",
    "def make_dataset(\n",
    "    image_paths: list,\n",
    "    batch_size: int = 1,\n",
    "    shuffle: bool = True,\n",
    "    resizeSize: typing.Optional[tuple] = (28,28), \n",
    "    resizeMethod: typing.Optional[str] = tf.image.ResizeMethod.LANCZOS3):\n",
    "    \"\"\"\n",
    "    Simple TF dataset creation\n",
    "    TODO: make TF Records\n",
    "    \"\"\"\n",
    "    imgs_tf_ls = list(load_tf_from_path(x, resizeSize, resizeMethod) for x in image_paths)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(imgs_tf_ls)\n",
    "    if shuffle:\n",
    "        N = dataset.__len__()\n",
    "        dataset = dataset.shuffle(N * 10)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def get_siamese_model(input_dim: tuple, rescaling=True):\n",
    "    input_layer = tf.keras.layers.Input(input_dim)\n",
    "    if rescaling:\n",
    "        rescaling_layer = lambda x: tf.keras.layers.Rescaling(1./255)(x)\n",
    "        input_layer = rescaling_layer(input_layer)\n",
    "        \n",
    "    conv2D = lambda input, filters: tf.keras.layers.Conv2D(filters, (3,3), padding='same', activation='swish')(input)\n",
    "    maxPool = lambda x: tf.keras.layers.MaxPool2D((2,2))(x)\n",
    "    flatten = lambda x: tf.keras.layers.Flatten()(x)\n",
    "    output_dense = lambda x, units: tf.keras.layers.Dense(units, activation=None)(x)\n",
    "    l2_normalize = lambda x: tf.math.l2_normalize(x, axis=-1) \n",
    "    \n",
    "    x1 = conv2D(input_layer, 16)\n",
    "    x2 = maxPool(x1)\n",
    "    x3 = conv2D(x2, 16)\n",
    "    x4 = maxPool(x3)\n",
    "    x5 = flatten(x4)\n",
    "    embeddingFeatures = output_dense(x5, 8)\n",
    "    embeddingFeatures = l2_normalize(embeddingFeatures) # normalize output features between 0 and 1\n",
    "\n",
    "    model = tf.keras.Model(input_layer, embeddingFeatures)\n",
    "    \n",
    "    # create siamese network\n",
    "    input1, input2 = tf.keras.layers.Input(input_dim), tf.keras.layers.Input(input_dim)\n",
    "    left_model = model(input1)\n",
    "    right_model = model(input2)\n",
    "    # dot product model\n",
    "    dot_product = tf.keras.layers.dot([left_model, right_model], axes=1, normalize=False) # sum(left * right)\n",
    "    # siamese model takes two input layers\n",
    "    siamese_model = tf.keras.Model(inputs=[input1, input2], outputs=dot_product, name='Siamese Model')\n",
    "    print(siamese_model.summary())\n",
    "    #plot_model(siamese_model, to_file='siamese_model.png')\n",
    "    return siamese_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model unit-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = list(map(lambda x: str(x), pathlib.Path(skimage.data_dir).glob('*.jpg')))\n",
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = load_tf_from_path(img_paths[0], (28,28))\n",
    "img_test.shape\n",
    "plt.imshow(img_test.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = get_siamese_model((28,28,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test_2 = load_tf_from_path(img_paths[1], (28,28))\n",
    "plt.imshow(img_test_2.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model([img_test, img_test])\n",
    "siamese_model([img_test_2, img_test_2])\n",
    "siamese_model([img_test, img_test_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = make_dataset(img_paths)\n",
    "for x in dataset:\n",
    "    plt.imshow(x.numpy()[0][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize_method = lambda x: tf.image.resize(x, (28,28), method=tf.image.ResizeMethod.LANCZOS3)\n",
    "# cast_method = lambda x: tf.cast(tf.round(tf.clip_by_value(x, 0, 255)), dtype=tf.uint8)\n",
    "\n",
    "# input_layer = tf.keras.layers.Input((28,28,3))\n",
    "# input_layer = cast_method(resize_method(input_layer))\n",
    "# if True:\n",
    "#     rescaling_layer = lambda x: tf.keras.layers.Rescaling(1./255)(x)\n",
    "#     input_layer = rescaling_layer(input_layer)\n",
    "\n",
    "\n",
    "# conv2D = lambda input, filters: tf.keras.layers.Conv2D(filters, (3,3), padding='same', activation='swish')(input)\n",
    "# maxPool = lambda x: tf.keras.layers.MaxPool2D((2,2))(x)\n",
    "# flatten = lambda x: tf.keras.layers.Flatten()(x)\n",
    "# output_dense = lambda x, units: tf.keras.layers.Dense(units, activation=None)(x)\n",
    "# l2_normalize = lambda x: tf.math.l2_normalize(x, axis=-1)\n",
    "# # sigmoid = lambda x: tf.keras.layers.Activation(activation='sigmoid')(x)\n",
    "\n",
    "# x1 = conv2D(input_layer, 16)\n",
    "# x2 = maxPool(x1)\n",
    "# x3 = conv2D(x2, 16)\n",
    "# x4 = maxPool(x3)\n",
    "# x5 = flatten(x4)\n",
    "# embedding = output_dense(x5, 8)\n",
    "# embedding = l2_normalize(embedding)\n",
    "# # embedding = sigmoid(embedding)\n",
    "# model = tf.keras.Model(input_layer, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # noise = tf.random.normal((1,1))\n",
    "# img_test_2 = read_tf_img(img_paths[1])\n",
    "# _ = plt.imshow(img_test_2.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = tf.image.resize(img_test_2, (28,28), method=tf.image.ResizeMethod.LANCZOS3)\n",
    "# i = tf.cast(tf.round(tf.clip_by_value(i, 0, 255)), dtype=tf.uint8) \n",
    "# plt.imshow(i.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left, right = model(img_test), model(img_test) \n",
    "# tf.keras.layers.dot([left, right], axes=1, normalize=False)\n",
    "# tf.reduce_sum(tf.math.multiply(left, right))\n",
    "# left, right = model(img_test), model(img_test_2) \n",
    "# tf.keras.layers.dot([left, right], axes=1, normalize=False)\n",
    "# tf.reduce_sum(tf.math.multiply(left, right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c97171bcbfabb853c7f677c58009c6eb5fb7956ea9e68d9c9c57fb3ed55f580"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venvTF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
